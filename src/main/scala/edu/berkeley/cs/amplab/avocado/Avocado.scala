package edu.berkeley.cs.amplab.avocado

import parquet.hadoop.{ParquetOutputFormat, ParquetInputFormat}
import spark.SparkContext
import spark.SparkContext._
import org.apache.hadoop.mapreduce.Job
import parquet.avro.{AvroParquetOutputFormat, AvroWriteSupport, AvroReadSupport}
import java.lang.Iterable
import com.google.common.io.Files
import java.io.File

object Avocado {

  def filterReads ()
  {
  }

  def processReads ()
  {
  }

  def filterPileups ()
  {
  }

  def callVariants ()
  {
  }

  def main (args: Array[String])
  {
    
  }
}
